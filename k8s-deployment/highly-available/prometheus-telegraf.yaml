---
apiVersion: v1
kind: Service
metadata:
  labels:
    name: prometheus
  name: prometheus
spec:
  selector:
    app: prometheus
  type: NodePort
  ports:
  - name: prometheus
    protocol: TCP
    port: 9090
    nodePort: 30900
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    name: prometheus-deployment
  name: prometheus-telegraf
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: prometheus
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"        
    spec:
      containers:
        - name: prometheus
          image: quay.io/prometheus/prometheus:v1.4.1
          imagePullPolicy: "Always"
          command:
            - "/bin/prometheus"
          args:
            - "-config.file=/etc/prometheus/prometheus.yml"
            - "-storage.local.path=/prometheus"
            - "-storage.local.retention=1h"
          ports:
          - containerPort: 9090
            protocol: TCP
          volumeMounts:
          - mountPath: "/etc/prometheus"
            name: prometheus-config-volume
        - name: "telegraf"
          image: "telegraf:1.1.2"
          imagePullPolicy: "Always"
          env:
           - name: INFLUXDB_K8S_NAMESPACE  # In PoC we assume that influxdb is in the same k8s namespace as telegraf
             valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace          
          volumeMounts:
            - mountPath: "/etc/telegraf"
              name: telegraf-config-volume
      volumes:
        - configMap:
            name: prometheus-config
          name: prometheus-config-volume
        - configMap:
            name: telegraf-config
          name: telegraf-config-volume
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: 30s
      scrape_timeout: 30s
    scrape_configs:
    - job_name: 'prometheus'
      static_configs:
        - targets: ['localhost:9090']
    - job_name: 'kubernetes-apiservers'
      kubernetes_sd_configs:
      - role: endpoints
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https
    - job_name: 'kubernetes-nodes'
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
    - job_name: 'kubernetes-service-endpoints'
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
        action: replace
        target_label: __scheme__
        regex: (https?)
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: (.+)(?::\d+);(\d+)
        replacement: $1:$2
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels: [__meta_kubernetes_service_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_service_name]
        action: replace
        target_label: kubernetes_name
    - job_name: 'kubernetes-services'
      metrics_path: /probe
      params:
        module: [http_2xx]
      kubernetes_sd_configs:
      - role: service
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
        action: keep
        regex: true
      - source_labels: [__address__]
        target_label: __param_target
      - target_label: __address__
        replacement: blackbox
      - source_labels: [__param_target]
        target_label: instance
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels: [__meta_kubernetes_service_namespace]
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_service_name]
        target_label: kubernetes_name
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_container_name]
        action: drop
        regex: telegraf
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: (.+):(?:\d+);(\d+)
        replacement: ${1}:${2}
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: telegraf-config
data:
  telegraf.conf: |
    # Telegraf Configuration
    #
    # Telegraf is entirely plugin driven. All metrics are gathered from the
    # declared inputs, and sent to the declared outputs.
    #
    # Plugins must be declared in here to be active.
    # To deactivate a plugin, comment out the name and any variables.
    #
    # Use 'telegraf -config telegraf.conf -test' to see what metrics a config
    # file would generate.
    #
    # Environment variables can be used anywhere in this config file, simply prepend
    # them with $. For strings the variable must be within quotes (ie, "$STR_VAR"),
    # for numbers and booleans they should be plain (ie, $INT_VAR, $BOOL_VAR)
    #
    #
    #
    # Global tags can be specified here in key="value" format.
    [global_tags]
        k8s_cluster="minikube"
    # Configuration for telegraf agent
    [agent]
        ## Default data collection interval for all inputs
        interval = "10s"
        ## Rounds collection interval to 'interval'
        ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
        round_interval = true
        ## Telegraf will send metrics to outputs in batches of at most
        ## metric_batch_size metrics.
        ## This controls the size of writes that Telegraf sends to output plugins.
        metric_batch_size = 1000
        ## For failed writes, telegraf will cache metric_buffer_limit metrics for each
        ## output, and will flush this buffer on a successful write. Oldest metrics
        ## are dropped first when this buffer fills.
        ## This buffer only fills when writes fail to output plugin(s).
        metric_buffer_limit = 10000
        ## Collection jitter is used to jitter the collection by a random amount.
        ## Each plugin will sleep for a random time within jitter before collecting.
        ## This can be used to avoid many plugins querying things like sysfs at the
        ## same time, which can have a measurable effect on the system.
        collection_jitter = "0s"
        ## Default flushing interval for all outputs. You shouldn't set this below
        ## interval. Maximum flush_interval will be flush_interval + flush_jitter
        flush_interval = "10s"
        ## Jitter the flush interval by a random amount. This is primarily to avoid
        ## large write spikes for users running a large number of telegraf instances.
        ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
        flush_jitter = "3s"
        ## By default, precision will be set to the same timestamp order as the
        ## collection interval, with the maximum being 1s.
        ## Precision will NOT be used for service inputs, such as logparser and statsd.
        ## Valid values are "ns", "us" (or "Âµs"), "ms", "s".
        precision = ""
        ## Logging configuration:
        ## Run telegraf with debug log messages.
        debug = false
        ## Run telegraf in quiet mode (error log messages only).
        quiet = false
        ## Specify the log file name. The empty string means to log to stderr.
        logfile = ""
        ## Override default hostname, if empty use os.Hostname()
        hostname = ""
        ## If set to true, do no set the "host" tag in the telegraf agent.
        omit_hostname = false
    # Configuration for influxdb server to send metrics to
    [[outputs.influxdb]]
        ## The full HTTP or UDP endpoint URL for your InfluxDB instance.
        ## Multiple urls can be specified as part of the same cluster,
        ## this means that only ONE of the urls will be written to each interval.
        # urls = ["udp://localhost:8089"] # UDP endpoint example
        urls = ["http://influxdb-0.influxdb-instances.$INFLUXDB_K8S_NAMESPACE.svc.cluster.local:8086"] # required
        ## The target database for metrics (telegraf will create it if not exists).
        database = "telegraf" # required
        ## Retention policy to write to. Empty string writes to the default rp.
        retention_policy = ""
        ## Write consistency (clusters only), can be: "any", "one", "quorum", "all"
        write_consistency = "any"
        ## Write timeout (for the InfluxDB client), formatted as a string.
        ## If not provided, will default to 5s. 0s means no timeout (not recommended).
        timeout = "5s"
        # username = "telegraf"
        # password = "metricsmetricsmetricsmetrics"
        ## Set the user agent for HTTP POSTs (can be useful for log differentiation)
        # user_agent = "telegraf"
        ## Set UDP payload size, defaults to InfluxDB UDP Client default (512 bytes)
        # udp_payload = 512# 
        ## Optional SSL Config
        # ssl_ca = "/etc/telegraf/ca.pem"
        # ssl_cert = "/etc/telegraf/cert.pem"
        # ssl_key = "/etc/telegraf/key.pem"
        ## Use SSL but skip chain & host verification
        # insecure_skip_verify = false
        # Read metrics from one or many prometheus clients
    [[outputs.influxdb]]
        ## The full HTTP or UDP endpoint URL for your InfluxDB instance.
        ## Multiple urls can be specified as part of the same cluster,
        ## this means that only ONE of the urls will be written to each interval.
        # urls = ["udp://localhost:8089"] # UDP endpoint example
        urls = ["http://influxdb-1.influxdb-instances.$INFLUXDB_K8S_NAMESPACE.svc.cluster.local:8086"] # required
        ## The target database for metrics (telegraf will create it if not exists).
        database = "telegraf" # required
        ## Retention policy to write to. Empty string writes to the default rp.
        retention_policy = ""
        ## Write consistency (clusters only), can be: "any", "one", "quorum", "all"
        write_consistency = "any"
        ## Write timeout (for the InfluxDB client), formatted as a string.
        ## If not provided, will default to 5s. 0s means no timeout (not recommended).
        timeout = "5s"
        # username = "telegraf"
        # password = "metricsmetricsmetricsmetrics"
        ## Set the user agent for HTTP POSTs (can be useful for log differentiation)
        # user_agent = "telegraf"
        ## Set UDP payload size, defaults to InfluxDB UDP Client default (512 bytes)
        # udp_payload = 512# 
        ## Optional SSL Config
        # ssl_ca = "/etc/telegraf/ca.pem"
        # ssl_cert = "/etc/telegraf/cert.pem"
        # ssl_key = "/etc/telegraf/key.pem"
        ## Use SSL but skip chain & host verification
        # insecure_skip_verify = false
        # Read metrics from one or many prometheus clients
    [[inputs.prometheus]]
        ## An array of urls to scrape metrics from.
        urls = ["http://localhost:9090/federate?match[]=%7Bjob%3D~\".%2B\"%7D"] # all metrics from prometheus
        ## Use bearer token for authorization
        # bearer_token = /path/to/bearer/token
        ## Optional SSL Config
        # ssl_ca = /path/to/cafile
        # ssl_cert = /path/to/certfile
        # ssl_key = /path/to/keyfile
        ## Use SSL but skip chain & host verification
        # insecure_skip_verify = false